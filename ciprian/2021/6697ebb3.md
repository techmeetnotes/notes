## -- title:       Using file-systems for structured-data editors
## -- library:     ideas
## -- identifier:  6697ebb3
## -- format:      commonmark
## -- timestamp:   2021-09-11 18:32:25


## Context

I've been skimming over Lion Kimbro's Discord server (especially the [#wikis](https://discord.com/channels/695746339019030619/824342692505845840) and [#programming](https://discord.com/channels/695746339019030619/811137425291214868) channels) and a lot of time the idea of tree-based editors came up when speaking about note taking or idea sharing.

From what I gather a tree-editor tries to structure information in nodes, that are organized in a strictly hierarchical tree structure, each node having some attributes (like title, summary or tags (what Lion calls "hooks"), content, etc.)  I would say that this concept could be generalized into a "structured" editor that would allow one to organize nodes in arbitrary graphs.

However, like most document editing systems, the entire tree (or graph) is saved in a self-contained single file (most likely using JSON, or another portable serialization format).

My counter-idea can be summarized as follows:  how about we use a file-system based structure (i.e. files, folders and symlinks) to store a particular tree / graph.

For referring to this document, please use the following URL:
https://scratchpad.volution.ro/ciprian/992c7f2944456f18cdde77f683f49aa7/6697ebb3.html




## File-system structure proposal

For starters, I'll take Lion's proposal of a simple node in such a tree structure:
> ~~~~
> {
>  "ID": "..."/#,  -- a unique identifier for the node
>  "TITLE": "..."/None,  -- the primary text of the item
>  "HOOK": "..."/None,  -- additional text to the side of the item
>  "FOLDED": true/false,
>  "ICON": ???,  -- an icon for the node [not sure how this is expressed]
>  "FOLDEDICON": ???,  -- another icon for the node? [not sure how...]
>  "DATA": {...},  -- arbitary data for the item,
>  "CHILDREN": [...]  -- populated with the same kind
> }
> ~~~~

Here is how I think one can use the file-system to serialize such a node:
* for each node there must be a folder "somewhere";  (there is a root, but we can ignore this for the moment);
* each node folder contains an `id.txt` file that holds a globally unique identifier for that node (serialized as one single UTF-8 line);  (one could use the path from the root for identifying a particular node, but we can ignore the path for reasons we'll see later;)
* each node folder also contains `title.txt` and `hook.txt` files that hold a number of UTF-8 lines for titles, respective hooks;  (a node could have multiple titles, say for aliasing, when two nodes were merged under a new title, but we want to keep the alternative titles for easy searching;)
* each node folder optionally contains an `icon.{png|ico|jpeg|...}` file that holds the icon in a native format (be it PNG, JPEG, etc.);
* each node folder optionally contains a `nodes` sub-folder (I renamed it from `children`), that contains other similarly structured nodes;
* however, the `nodes` sub-folder can contain symlinks to other nodes, thus one can get a graph;  (we could say that proper sub-folders are actual children, meanwhile symlinks are a sort-of a bridge to another sub-tree somewhere;)
* each node folder contains a `data` sub-folder, where one can just dump any type of file, say a `readme.md`, `some-data.csv`, `some-plot.png`, all pertaining to that node;  (this is sort of an "attachments" folder;)




## Advantages

Here are some unique advantages of using a proper file-system for serializing such nodes:
* one can use whatever tool one likes to browse, search, edit and manage such a structure;  (be it `mc`, `find`, `grep`, `sed`, `nano`, `emacs`, etc.;)
* one can easily implement custom tools, in many languages, to interact with this structure;  (there is no need for a library or RPC based API;  the file-system is the API;)
* it efficiently supports any kind of file format (as part of the `data` sub-folder), especially binary ones that are not easily expressible in JSON;  (moreover, these files can be managed with their native editor, given they are a plain file;)
* backup or remote synchronizing the structure through countless tools (for example `rsync`, `tar`, `cpio`, `zip`, etc.);
* versioning or snapshotting the structure through tools such as `git`, `hg`, etc.;




## Disadvantages

File-systems in general are nice, until you hit the following issues:
* storing many small files (say under 4KiB) results in storage overhead, and increased read-write latency, especially on classic rotating disks;
* any operation is mediated by the OS kernel, thus batch operations will have increased CPU usage;
* also, batch operations can increase wear-and-tear on SSD's and other flash-based storage;
* it's impossible to impose a schema;  (at best one can write a tool to validate an existing structure;)
* although one can use any tool to browse and manage this structure it is cumbersome;  creating a new node implies also `touch`-ing a couple of files and `mkdir`-ing a couple of sub-folders;

(However, most of these can be mitigated by using a FUSE / 9p synthetic file-system as described later.)




## Extensions

### Live trees
Say we want to have "live nodes", then we can add an `actions` folder that contains executable scripts, which when run should do something useful in the context of that node.

### Federated trees
Say we want to have "federated trees", then just symlink the root of one tree as a child in some other tree `nodes` folder.

### Real-time trees
Say we want to immediately execute an action when a node changes (like for example exporting it to a static HTML page), then one can choose one of these simple techniques:
* use the modified timestamp of the files and folders to detect the changed nodes since the last run;  (perhaps have the application always touch some central "tree is dirty" file, so that the tool has to only check one file to detect changes, and only then walk the entire tree to find the changed nodes;)
* use the one of the OS "file-system change API" (Linux has 3 of them, [fanotify](https://man7.org/linux/man-pages/man7/fanotify.7.html), [inotify](https://man7.org/linux/man-pages/man7/inotify.7.html), [dnotify](https://man7.org/linux/man-pages/man2/fcntl.2.html)) and listen for changes in real-time;
* use a "file-system watcher" tool, that uses one of the API's above, and when a change is detected it can call another tool;  (an example of such a watcher tool is [watchexec](https://github.com/watchexec/watchexec);)
* use the `changelog` folder as described next;

### RSS for trees
Say we want to build an RSS of the changes done to the tree:  have a `changes`, `changelog` or similar folder, where each process modifying a node would create a JSON file containing pertinent information that can be used to create an RSS entry (like title, author, diff, timestamp, etc.).  (This idea was initially proposed by Lion as a solution to the "real-time trees", but I think it makes more sense for building a feed.)




## FUSE / 9p daemon

However, one can have this file-system be a synthetic one exposed via FUSE or 9p:
* there is a daemon written in some language (say C, Go, Rust, Python, etc.) that just exposes a file-system and backs it in a "database";  (one could use SQLite, one of the countless embedded key-value datastores like LMDB, RocksDB, etc.;)
* that daemon can also impose the structure:  one creates a new node folder through `mkdir`, the daemon automatically creates the files for `id.txt` (perhaps prefilled with a random token), empty `title.txt` and `hook.txt` files, empty `nodes` sub-folder, etc.;
* any edit of such a synthetic file is mediated by the daemon, thus syntax and other rules can be checked;

Moreover, one can also start implementing extensions like:
* say we want "live objects" as described above, for each `some-action.src` script (that can be edited by the user), there are `some-action.do` executable or `some-action.out` files, that when the `*.do` is executed or the `*.out` is opened for reading, the daemon starts the `*.src` script with the current working directory being the current node folder;  (this process is started as a child of the daemon process for reasons explained afterwards regarding remote daemons;)
* all this can be mounted over the network (if ones goes with 9p), thus "live objects" are executed on the remote host not on the client host;
* a `metadata.json` file can be computed on the fly by the daemon, containing the original JSON object Lion described;
* all sorts of "indices" and "maps" can be computed by the daemon;
* easily exporting over HTTP, even with a simple server;




## Thoughts

Although above I've discussed only about file-systems, nothing stops one to implement a nice graphical UI that interacts with this file-system.  (As stated, the file-system is actually the API for the underlying structure.)

Is it optimal?  Not quite:
* you can't easily cache the data in the UI (because something can always change it via the file-system);
* there is some overhead (there is the daemon, there is the OS kernel, etc);
* there is some latency (even with a fast SSD, reading a file is slower than reading directly from RAM);

However, I think for the intended use-case (i.e. a local tool used by a person) all this overhead is minimal when compared to the flexibility and other advantages.




## Discussions

These ideas were first discussed in the [#programming](https://discord.com/channels/695746339019030619/882877592179449936) Discord channel (actually a thread), and I've selected a few messages that are not reflected in my writing above.


> [Ciprian]
>
> I've used TreeLine to look at Lion's universal ID proposal.  Being new to that tool I was confused by it's UI especially because it was hard to discover what information was actually there.  For example it took me at least 5 minutes (and I've found this by mistake) that some nodes had actually "text" tied to them that elaborated on the title-line.  Aside from that, me being more accustomed to using the terminal, I found the mouse-driven UI hindering.
>
> How could my experience have been better:
> * I've tried to find an export to HTML, but none of the options also contained the notes;
> * a plain-text, read from top-to-bottom, export would have helped me read it better;


> [Ciprian]
>
> JSON is nice as it is nearly universally implemented, and its object model fits almost all programming languages (i.e. for most languages there is a list, map, string, etc.).
>
> However it has lots of shortcomings with regard to structured data:
> * no binary support;  (yes, one can use Base64, but that is not optimal);  thus one can't embed images, HTML, Markdown, Excel files, etc. inside JSON without issues;
> * high overhead for compact structures (such as data matrices, even when compared to CSV, TSV);


> [Lion]
>
> I wonder if the performance is going to be okay -- looking at a tree with say, 100 nodes in it, entails zipping through a few hundred files...?  I don't know if that is fast enough, or not.  But it's certainly feasible.  I do worry about the small-file block size -- storing 100 bytes becoming 4kiB, and doing so over and over.  But that's small potatoes too, for trees of certain sizes.
>
> There's an implication that multiple programs are going to be touching the data, which introduces race conditions -- something I've thought a lot about with respect to my "Filetalk" system.
>
> I ended up concluding that by convention, each file has a policy about who writes, who reads, and how filenames are constructed for non-collision, including process identification procedures.


> [Ciprian]
>
> Indeed, if one would to use a classical file-system say Ext4 family, FAT, and most other block-based file-systems, then even 1 byte would become 4KiB. On the other hand there are filesystems like the defunct ReiserFS (and it seems NTFS also) that do store small files inside the directory tree.
>
> However that is why I've mentioned a 9p / FUSE "daemon" that just exposes a file-system but stores everything in an embedded database like SQLite or one of the embedded key-value databases like LMDB, RocksDB or BoltDB (for Go).  Then storage becomes an non-issue.
>
> About file-operations (`zip`-ing  everything, etc.) indeed they are suboptimal, but possible.  The file-system is just an API towards the tree-structure database (handled by the "daemon");  it is an API that is implementable by virtually any language that exists (even ones that don't have support for sockets), and furthermore is usable by normal tools like `mc`.  It is also suboptimal for bulk / batch operations (say creating, editing thousands of nodes per second), but given that each interaction is a consequence of a human interaction then this doesn't impact much.


> [Ciprian]
>
> I think race-conditions are a mater of fact with any IPC-based API, be it HTTP, Unix domain sockets, pipes, and even communication via the file-system.  The tools must be written in such a manner that they collaborate.
>
> However, getting back to our "daemon" that sits behind the file-system, it can also serialize access and impose locks.  For example while anyone is walking the file-structure (i.e. there is a pending `readdir` operation which keeps open a file-descriptor to a directory), any write operations are held back with a global read-write lock (implemented by the daemon).  But in the end race-conditions are seldom, and I don't think are catastrophic.  (I.e. a race condition can at most affect one "node", thus the blast area is limited.)


> [Lion]
>
> Very quickly --
> * I want to call the "tree data implemented via a file system" something, so I'll call it, "Tree By Files" for the time being.
> * One of my constraints for myself is that whatever system I write, it rides on top of typical run-of-the-mill unsurprising system configurations.  I allow for Python to need to be installed, or some collection of standard files (msvcrt.dll or whatever it's called,) -- but a backend database system that plugs into the operating system, I'm a little leery of -- for my own aims, that is.  I have a focus on "lightweight," if you wil.
> * There's a simple fix -- just have a single JSON file in the directory, called "NODE.json", and that solves the disk problems, at the price that the consumer must not only read, but read and interpret, the file.


> [Ciprian]
>
> Regarding the database backend:  all the solutions I've proposed (SQLite3, LMDB, RocksDB, LevelDB, BoltDB, etc.) are "embedded databases", i.e. they are libraries that run as part of the application process and store their data is some files on the disk.  Basically there is no difference between "one large JSON file" and the "one large folder with the DB data".  Depending on the programming language and portability requirements I think the safest bet is SQLite3.
