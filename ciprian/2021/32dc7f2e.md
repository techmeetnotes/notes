## -- title:       `token-fs` -- secure ephemeral file-system
## -- library:     ideas
## -- identifier:  32dc7f2e
## -- format:      commonmark
## -- timestamp:   2021-10-10 18:56:29


## The problem

There are many applications that need to (can only) share sensitive data through files (either via file paths, or open file descriptors), especially scripts that wrap other tools.

By sensitive data, I mainly mean passwords, API keys, or other secret information that should not leak into permanent storage.

A very common example that can be seen in many shell scripts is as follows:
~~~~
token="$( obtain-token ... )"
command <<<"${token}"
~~~~

The main problem with this example is that, at least with `bash` until recently, it uses the common technique of create temporary file (in `${TMPDIR}`), delete that file but keep the file descriptor open, write the data, use that file descriptor as the new process `stdin`.

Unfortunately, if `${TMPDIR}` is mounted on a persistent file-system (i.e. Ext4, BTRFS, etc.), although the file is deleted, its contents may still be recovered from the raw disk.  Using full-disk-encryption is somewhat more secure, but still the data might remain there for long periods of time, especially on large disks with lots of free space.  Using `tmpfs` is somewhat even more secure, but still if one uses swap without full-disk-encryption we are back at square one.

(As a sidenote, a common work-around is to use pipes.  This mostly works with tools that read the file only once, and if the data is somewhat small, under 16 KiB on most POSIX systems.)

(Another alternative is to use environment variables, like many tools do, but that has its own problems.)




## A potential solution

One solution, that I'm proposing here, is having a FUSE-based file-system that exposes a synthetic file-system specially designed for this use-case.  (Given that FUSE is supported on many OS's, from Linux to OSX and BSD's to Windows, it could potentially work on any of these, however here I mainly analyze it from a Linux implementation point of view.)

This FUSE-based file-system, that I'll name `token-fs` from here on, should have two API's (a file-system, especially a synthetic one, could be seen as an API):
* one for managing tokens, i.e. creating, deleting, altering, etc.;
* one for accessing tokens, i.e. reading the sensitive data, thus these paths are to be passed to other tools to read from;
* (the "files" handled by both these API's I'll call them "tokens" from here on;)

As features, I see the following "core requirements":
* in-memory only storage (i.e. not leaking into swap or disk);
* larger token sizes (say up to 1MiB individually, and 1 GiB in total) -- this allows one to store not only passwords, but other larger files like SSH private keys, or even configuration files (that might contain sensitive data);
* ephemeral tokens -- this allows one to export a secret, that can be reused by an application, but only for a certain amount of time;  (especially useful with SSH private keys, or other cryptographic material that we don't want exposed forever;)
* one-time-use / limited-use tokens -- if ephemeral tokens limit the availability window in seconds, this feature limits the availability window in access counts;  (by combining both ephemeral and limited-use tokens, we could implement something like:  "this password can be used only once in the next minute";)
* confirmation on token access -- each time a new process tries to access a given token, the user is presented with a confirmation;  (similar to how `ssh-agent` or `gpg-agent` implement it;)

Additional features might include:
* dynamic tokens -- one could define a token that when accessed, the FUSE daemon actually starts a process to provide its data (for example a `gpg` wrapper, or perhaps even `oathtool` to generate TOTP tokens);
* persistent tokens -- extending upon the previous feature, when a token is accessed for writing, the FUSE daemon starts a process to persist the new data (again for example a `gpg` wrapper);
* remote agent -- just like SSH has the option to forward the `ssh-agent`, so could `token-fs` be exported to remote systems via a custom protocol;

Given how FUSE works, one could have a single `token-fs` mounted on the system shared by users, or each user could have it's own `token-fs` instance.  (The shared one might not offer dynamic or persistent tokens, meanwhile the idividual one might.)




## Example

Here are a few examples on how such a tool might be used.

I assume the following:
* that `token-fs` is mounted on `/mnt/tokens`;
* the variable `_token_id` is randomly generated (via `uuidgen`), but if needed can be selected by the user, if for example the resulting path is hard-coded into a persistent configuration file;)
* wherever I write `echo secret`, I mean any tool that writes on `stdout` the sensitive data;  (for example `gpg2 -d < .../secret.gpg`;)

~~~~
## create a new token (with default options)
_token_id="$( uuidgen -r )"
echo password > "/mnt/tokens/${_token_id}"

## use the token
some-tool --password "/mnt/tokens/${_token_id}"
~~~~

~~~~
## create a new token, with custom options
_token_id="$( uuidgen -r )"
echo password | token-fs create --id "${_token_id}" --expire-after 1hour --usage-limit 3
~~~~

~~~~
## create a new token, with custom options, and identifier chosen by `token-fs`
_token_id="$( echo password | token-fs create --expire-after 1hour --usage-limit 3 --output identifier )"

## create a new token, same as above, but get the path
_token_path="$( echo password | token-fs create --expire-after 1hour --usage-limit 3 --output path )"
~~~~

~~~~
## destroy a token once used
rm "/mnt/tokens/${_token_id}"

## or
token-fs destroy --id "${_token_id}"
~~~~

~~~~
## destroy everything (for example before going to sleep)
token-fs destroy-all
~~~~




## Implementation details (for Linux)

Here are a few implementation details, as available on Linux, that might enhance the security of `token-fs`:
* enabling the FUSE `default_permissions` mount option -- one can change the access of the secret (from user-only, to world-readable) via `chmod`, and the kernel will check the file-system permissions just like with other file-systems;
* disabling the FUSE  `allow_other` mount option -- regardless of the file-system permissions, only the user that runs the `token-fs` daemon can access its files;
* disabling the FUSE `allow_root` mount option -- in addition to the above, not even `root` is allowed to access the tokens;  (although `root` might just read the `token-fs` daemon memory and extract what it needs;  but this is nice against accidental exposure;)
* enabling the FUSE `direct_io` and disabling `kernel_cache` (and `auto_cache`) mount options -- when a process reads a token file, the data is not cached by the kernel, thus we eliminate one possible leak vector;
* using [mlock](<https://man7.org/linux/man-pages/man2/mlock.2.html>) functions -- we make sure that our `token-fs` memory doesn't leak to swap;
* using `memfd_secret` (as described in [this LWN article](<https://lwn.net/Articles/865256/>)) -- one can even keep memory inaccessible by the kernel, thus again limiting the attack vectors;




## Prior-art

* <https://github.com/arhat-dev/credentialfs>;
* <https://github.com/rmind/rvault>;
* <https://github.com/zbiljic/memfs>;
* <https://github.com/netheril96/securefs>;
* <https://github.com/JPT580/gpgfs>;
* <https://github.com/fphammerle/rgpgfs>;
